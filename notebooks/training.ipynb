{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def load_data(path: str):\n",
    "    data = pd.read_csv(path).drop(['Age', 'Gender', 'Snoring', 'Swallowing Difficulty'], axis=1)\n",
    "    data['Level'] = data['Level'].map({'Normal': 0, 'Benign': 1, 'Malignant': 2})\n",
    "\n",
    "    sampler = RandomOverSampler(random_state=3)\n",
    "    X, y = sampler.fit_resample(data.drop('Level', axis=1), data['Level'])\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=7, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "\n",
    "\n",
    "import json\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, _, y_train, _ = load_data('../data/small_cancer_data.csv')\n",
    "\n",
    "# (enabled, name, cls, param_grid)\n",
    "tuning_specs = [\n",
    "    (1, 'ada', AdaBoostClassifier, {\n",
    "        'estimator': [DecisionTreeClassifier(), ExtraTreeClassifier()],\n",
    "        'n_estimators': [i * 50 for i in range(1, 5)],\n",
    "        'learning_rate': [i * 0.05 for i in range(1, 11)]\n",
    "    }),\n",
    "    (1, 'gbc', GradientBoostingClassifier, {\n",
    "        'learning_rate': [i * 0.05 for i in range(1, 11)],\n",
    "        'n_estimators': [i * 50 for i in range(1, 5)],\n",
    "        'max_depth': [i * 5 for i in range(1, 4)]\n",
    "    }),\n",
    "    (1, 'rfc', RandomForestClassifier, {\n",
    "        'n_estimators': [i * 100 for i in range(1, 11)],\n",
    "        'max_depth': [i * 5 for i in range(1, 4)],\n",
    "        'min_samples_split': [i * 2 for i in range(1, 6)],\n",
    "        'min_samples_leaf': [i * 2 for i in range(1, 6)],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }),\n",
    "    (1, 'log', LogisticRegression, {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [10 ** i for i in range(-3, 4)],\n",
    "        'max_iter': [i * 500 for i in range(1, 6)]\n",
    "    }),\n",
    "    (1, 'gnb', GaussianNB, {}),\n",
    "    (1, 'knn', KNeighborsClassifier, {\n",
    "        'n_neighbors': [i * 2 for i in range(2, 11)],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree'],\n",
    "        'leaf_size': [i * 10 for i in range(1, 11)]\n",
    "    }),\n",
    "    (1, 'mlp', MLPClassifier, {\n",
    "        'hidden_layer_sizes': [(i * 10,) for i in range(1, 5)],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "        'alpha': [10 ** i for i in range(-4, 0)],\n",
    "        'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "        'batch_size': [i * 100 for i in range(1, 11)]\n",
    "    }),\n",
    "    (1, 'svc', SVC, {\n",
    "        'C': [10 ** i for i in range(-3, 4)],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'gamma': [10 ** i for i in range(-3, 4)]\n",
    "    })\n",
    "]\n",
    "with open('../models/tuned_hyperparams.json', 'r') as f:\n",
    "    tuned_hyperparams = json.load(f)\n",
    "\n",
    "for enabled, name, cls, param_grid in tuning_specs:\n",
    "    if enabled:\n",
    "        print(str.center(name.upper(), 35, '-'))\n",
    "        model = GridSearchCV(cls(random_state=3), param_grid, n_jobs=2, verbose=2)\n",
    "        model.fit(X_train, y_train)\n",
    "        tuned_hyperparams[name] = model.best_params_\n",
    "\n",
    "with open('../models/tuned_hyperparams.json', 'w') as f:\n",
    "    json.dump(tuned_hyperparams, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
